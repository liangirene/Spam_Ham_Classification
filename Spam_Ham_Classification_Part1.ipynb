{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw9.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam/Ham Classification\n",
    "## Feature Engineering, Logistic Regression, Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "proj2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Description\n",
    "We create a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails.\n",
    "\n",
    "- Feature engineering with text data\n",
    "- Using `sklearn` libraries to process data and fit models\n",
    "- Validating the performance of your model and minimizing overfitting\n",
    "- Generating and analyzing precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part I - Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:41.341673Z",
     "start_time": "2019-04-03T20:17:41.330307Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Loading in the Data\n",
    "\n",
    "In email classification, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the unlabeled test set contains 1000 unlabeled examples.\n",
    "\n",
    "Run the following cells to load in the data into DataFrames.\n",
    "\n",
    "The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example\n",
    "1. `subject`: The subject of the email\n",
    "1. `email`: The text of the email\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n",
    "\n",
    "The `test` DataFrame contains 1000 unlabeled emails. You will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.181245Z",
     "start_time": "2019-04-03T20:17:41.343927Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version already downloaded: Fri Apr  9 21:35:13 2021\n",
      "MD5 hash of file: 0380c4cf72746622947b9ca5db9b8be8\n",
      "Using version already downloaded: Fri Apr  9 21:35:14 2021\n",
      "MD5 hash of file: a2e7abd8c7d9abf6e6fafc1d1f9ee6bf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...     0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...     1  \n",
       "3  depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import fetch_and_cache_gdrive\n",
    "fetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\n",
    "fetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n",
    "\n",
    "original_training_data = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34476156ed73b800",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "First, let's check if our data contains any missing values. We have filled in the cell below to print the number of NaN values in each column. If there are NaN values, we replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns will be replaced with empty strings). Finally, we print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n",
    "\n",
    "Note that while there are no NaN values in the `spam` column, we should be careful when replacing NaN labels. Doing so without consideration may introduce significant bias into our model when fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "id         0\n",
      "subject    6\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n",
      "------------\n",
      "After imputation:\n",
      "id         0\n",
      "subject    0\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Before imputation:')\n",
    "print(original_training_data.isnull().sum())\n",
    "original_training_data = original_training_data.fillna('')\n",
    "print('------------')\n",
    "print('After imputation:')\n",
    "print(original_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "In the cell below, we have printed the text of the `email` field for the first ham and the first spam email in the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.247245Z",
     "start_time": "2019-04-03T20:17:42.228451Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: http://boingboing.net/#85534171\n",
      " date: not supplied\n",
      " \n",
      " arts and letters daily, a wonderful and dense blog, has folded up its tent due \n",
      " to the bankruptcy of its parent company. a&l daily will be auctioned off by the \n",
      " receivers. link[1] discuss[2] (_thanks, misha!_)\n",
      " \n",
      " [1] http://www.aldaily.com/\n",
      " [2] http://www.quicktopic.com/boing/h/zlfterjnd6jf\n",
      " \n",
      " \n",
      "\n",
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      " <font size=3d\"4\"><b> a man endowed with a 7-8\" hammer is simply<br>\n",
      "  better equipped than a man with a 5-6\"hammer. <br>\n",
      " <br>would you rather have<br>more than enough to get the job done or fall =\n",
      " short. it's totally up<br>to you. our methods are guaranteed to increase y=\n",
      " our size by 1-3\"<br> <a href=3d\"http://209.163.187.47/cgi-bin/index.php?10=\n",
      " 004\">come in here and see how</a>\n",
      " </body>\n",
      " </html>\n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0]\n",
    "first_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0]\n",
    "print(first_ham)\n",
    "print(first_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Discuss one thing you notice that is different between the two emails that might relate to the identification of spam.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is different between the two emails that might relate to the identification of spam is that unlike the ham email, the spam email seems to be meant for a very general audience instead of a specific person since it does not mention any names (ham email includes the name Misha) and does not have a signature block (\"thanks, misha!\"). Further, the spam email is written in html while the ham email is in strings, which make the ham email more readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78513403ef52a957",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Training Validation Split\n",
    "The training data we downloaded is all the data we have available for both training models and **validating** the models that we train.  We therefore need to split the training data into separate training and validation datsets.  You will need this **validation data** to assess the performance of your classifier once you are finished training. Note that we set the seed (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic Feature Engineering\n",
    "\n",
    "We would like to take the text of an email and predict whether the email is ham or spam. This is a *classification* problem, so we can use logistic regression to train a classifier. Recall that to train a logistic regression model we need a numeric feature matrix $X$ and a vector of corresponding binary labels $y$.  Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "Each row of $X$ is an email. Each column of $X$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n",
    "\n",
    "```\n",
    ">>> words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))\n",
    "\n",
    "array([[1, 0, 0],\n",
    "       [1, 0, 1]])\n",
    "```\n",
    "\n",
    "*The provided tests make sure that your function works correctly, so that you can use it for future questions.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.337281Z",
     "start_time": "2019-04-03T20:17:42.320567Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list): words to find\n",
    "        texts (Series): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    #for i in texts: \n",
    "        #contain_list = [texts.str.contains(x) for x in words]\n",
    "        #result = pd.DataFrame(contain_list).astype(int)\n",
    "        #indicator_array = []\n",
    "        \n",
    "        #for i in result.columns:\n",
    "            #answ = result[i].to_list()\n",
    "            #indicator_array.append(answ)     \n",
    "    #return np.array(indicator_array)\n",
    "\n",
    "    indicator_array = []\n",
    "    for text in texts:\n",
    "        array = []\n",
    "        for word in words:\n",
    "            if word in text:\n",
    "                array.append(1)\n",
    "            else:\n",
    "                array.append(0)\n",
    "        indicator_array.append(array)\n",
    "    return np.array(indicator_array)\n",
    "\n",
    "words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q2</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q2 passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eda",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic EDA\n",
    "\n",
    "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. If the feature is itself a binary indicator, such as whether a certain word occurs in the text, this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following plot (which was created using `sns.barplot`) compares the proportion of emails in each class containing a particular set of words. \n",
    "\n",
    "![training conditional proportions](images/training_conditional_proportions.png)\n",
    "\n",
    "You can use DataFrame's `.melt` method to \"unpivot\" a DataFrame. See the following code cell for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.428419Z",
     "start_time": "2019-04-03T20:17:42.386697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_1  word_2  type\n",
       "0       1       0  spam\n",
       "1       0       1   ham\n",
       "2       1       0   ham\n",
       "3       0       1   ham"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type variable  value\n",
       "0  spam   word_1      1\n",
       "1   ham   word_1      0\n",
       "2   ham   word_1      1\n",
       "3   ham   word_1      0\n",
       "4  spam   word_2      0\n",
       "5   ham   word_2      1\n",
       "6   ham   word_2      0\n",
       "7   ham   word_2      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "df = pd.DataFrame({\n",
    "    'word_1': [1, 0, 1, 0],\n",
    "    'word_2': [0, 1, 0, 1],\n",
    "    'type': ['spam', 'ham', 'ham', 'ham']\n",
    "})\n",
    "display(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\n",
    "display(df);\n",
    "display(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\n",
    "display(df.melt(\"type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Make sure to only consider emails from `train`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "manual: True\n",
    "format: image\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.145246Z",
     "start_time": "2019-04-03T20:17:42.430406Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n",
    "\n",
    "word_list = [\"today\", \"like\", \"need\", \"help\", \"free\", \"deal\"]\n",
    "ham = train[train['spam'] == 0][\"email\"]\n",
    "spam = train[train['spam'] == 1][\"email\"]\n",
    "ham_array = words_in_texts(word_list, ham)\n",
    "spam_array = words_in_texts(word_list, spam)\n",
    "\n",
    "bar_width = 0.3\n",
    "plt.bar(x = word_list, align = \"edge\", height = np.sum(ham_array, axis = 0)/len(ham_array), label = \"Ham\", width = -bar_width)\n",
    "plt.bar(x = word_list, align = \"edge\", height = np.sum(spam_array, axis = 0)/len(spam_array), label = \"Spam\", width = bar_width)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Proportion of Emails\")\n",
    "plt.title(\"Frequency of Words in Spam/Ham Emails\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic Classification\n",
    "\n",
    "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "We've given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n",
    "\n",
    "`X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n",
    "\n",
    "`Y_train` should be a vector of the correct labels for each email in the training set.\n",
    "\n",
    "*The provided tests check that the dimensions of your feature matrix (X) are correct, and that your features and labels are binary (i.e. consists of only 0's and 1's). It does not check that your function is correct; that was verified in a previous question.*\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: spam, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = np.array(words_in_texts(some_words, train['email'])).astype(int)\n",
    "Y_train = train['spam']\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q4</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q4 passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Now that we have matrices, we can build a model with `scikit-learn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.75$\n",
    "\n",
    "*The provided test checks that you initialized your logistic regression model correctly.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q5</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q5 passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't seem too shabby! But the classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will hold out some of our data for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
    "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam. \n",
    "\n",
    "The two graphics below may help you understand precision and recall visually:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6a\n",
    "\n",
    "Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (feel free to hard code your answers for this part):\n",
    "\n",
    "*Tests in Question 6 only check that you have assigned appropriate types of values to each response variable, but do not check that your answers are correct.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:20:13.853633Z",
     "start_time": "2019-04-03T20:20:13.825724Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1918)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_fp = 0\n",
    "#ham (0) email predicted as spam (1) is 0 because the classifier never predicts spam (1)\n",
    "zero_predictor_fn = sum(Y_train == 1)\n",
    "#spam (1) email predicted as ham (0) is the total number of spam emails because all spam emails are misclassified\n",
    "zero_predictor_fp, zero_predictor_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q6a</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q6a passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "What is the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:23:21.553134Z",
     "start_time": "2019-04-03T20:23:21.548219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7447091707706642, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_acc = sum(Y_train == 0) / len(Y_train)\n",
    "#of points classified correctly / # points total\n",
    "zero_predictor_recall = 0\n",
    "#never predicts 0 (positive), so the model never correctly predicts the positive class --> tp is 0 \n",
    "zero_predictor_acc, zero_predictor_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q6b</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q6b passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6c\n",
    "\n",
    "Provide brief explanations of the results from 6a and 6b. Why do we observe each of these values (FP, FN, accuracy, recall)?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive (FP): the classifier never predicts spam/positive (1), so there can't be any false positives, resulting in a 0 FP.\n",
    "\n",
    "False Negative (FN): the classifier flags all spam/positive (1) emails as ham (0), so all the spam/positive emails are misclassified as negatives, resulting in the FN value as the total number of spam emails in the data.\n",
    "\n",
    "Accuracy: defined as the (number of data classified correctly)/(number of data in total). The number of data classified correctly is the number of ham emails since the classifier always predicts ham/negative (0) and the number of total data is the length of Y_train.\n",
    "\n",
    "Recall: defined as TP/(TP+FN), or the proportion of spam/positive (1) emails accurately predicted as such. Since the classifier never predicts spam/positive (1), it never correctly flags the positive class, resulting in a 0 recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 6d\n",
    "\n",
    "Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 5. Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:37:54.875265Z",
     "start_time": "2019-04-03T20:37:54.720667Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "TP = np.sum((y_pred == 1) & (Y_train == 1))\n",
    "FP = np.sum((y_pred == 1) & (Y_train == 0))\n",
    "TN = np.sum((y_pred == 0) & (Y_train == 0))\n",
    "FN = np.sum((y_pred == 0) & (Y_train == 1))\n",
    "\n",
    "logistic_predictor_precision = TP / (TP + FP)\n",
    "logistic_predictor_recall = TP / (TP + FN)\n",
    "logistic_predictor_far = FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q6d</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q6d passed!"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6e\n",
    "\n",
    "Are there more false positives or false negatives when using the logistic regression classifier from Question 5?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6e\n",
    "manual: True\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the logistic regression classifier from Question 5, there are more false negatives (1699) than false positives (122)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6f\n",
    "\n",
    "1. Our logistic regression classifier got 75.76% prediction accuracy (number of correct predictions / total). How does this compare with predicting 0 for every email?\n",
    "1. Given the word features we gave you above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
    "1. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6f\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The classifier that predicts 0 for ever email has a prediction accuracy of 74.47%, so our logistic regression classifier performs slightly better in comparison since it has a 75.76% prediction accuracy.\n",
    "\n",
    "2. This classifier is performing poorly because the word features that were used are not common/present in many of the email sets, so it cannot predict whether the email is spam or ham based on the word features, resulting in multiple rows of 0's in X_train.\n",
    "\n",
    "3. I would prefer the logistic regression classifier as it not only has a higher accuracy rate, but also a higher recall rate, meaning that it is better at flagging spam emails as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q2</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q4</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q5</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q6a</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q6b</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q6d</strong> passed!</p>\n",
       "    \n",
       "\n"
      ],
      "text/plain": [
       "q2 passed!\n",
       "\n",
       "q4 passed!\n",
       "\n",
       "q5 passed!\n",
       "\n",
       "q6a passed!\n",
       "\n",
       "q6b passed!\n",
       "\n",
       "q6d passed!\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"hw9.zip\" target=\"_blank\">here</a>\n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
